---
title: "The Effects of Class Type on Math Score for the 1st Grade Students"
author: "Kenneth Lee, Xialin Sang, Rong Duan, Chen Zhang"
date: "12/01/2020"
output:
  html_document:
    df_print: paged
    fig_caption: yes
  pdf_document: default
---

<style type="text/css">

body{ /* Normal  */
      font-size: 18px;
  }

</style>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
***
Team ID: Team 2

Kenneth Lee: Wrote sections 1.1, 1.2, 2.1, 2.2, 2.3. Plot the graphs for descriptive analysis.

Rong Duan: Model Diagnostics

Xialin Sang: Hypothesis Testing

Chen Zhang: Mainly task 8 & organization of the report
***

## 1. Introduction

### 1.1 Background
The effects of class sizes on student achievement is an important topic for policy makers in American K-12 education system. While some think that it is expensive to maintain small classes at school, others may argue that small classes can improve student performance. As such, this work aims to study the effects of class type on 1st grade student's test scores in Mathematics. Our study is based on a dataset generated by a four-year longitudinal class-size randomized study from 1985 to 1989 called The Student/Teacher Achievement Ratio (STAR) conducted by the State Department of Education in Tennessee. 

The primary scientific question of interest is whether there is a treatment effect of assigning various class types to the student's performance on tests scores in Mathematics. In this study, we implement exploratory data analysis, one-way anova model, model diagnostics, hypothesis testing. In the end, we conclude our findings and discuss any causal statements that could possibly be made based on our analysis and assumptions.

### 1.2 Statistical questions of interest

To answer the primary scientific question of interest, we propose to fit a single factor anova model with the quantitative test scores as the response variable and the class type as the predictor variable. We will then run our model diagonstics to see if the assumptions of the model hold and test whether or not there is a treatment effect on the test scores. 

## 2. Analysis Plan

### 2.1 Population and study design
According to the description of the dataset, over 7,000 students in 79 schools were randomly assigned into one of three different treatments: small class (13 to 17 students per teacher), regular class (22 to 25 students per teacher), and regular-with-aide class (22 to 25 students with a full-time teacher's aide) [1]. Classroom teachers were also randomly assigned to the classes they would teach. The original study captures data from one single cohort progressing from kindegarten to third grade, but we will only focus on the data about the 1st grade students as they are our study targets. 

### 2.2 Descriptive Analysis

First of all, we will provide some background information about the dataset such as the number of rows and columns, the number of missing values, the number of continuous columns and the number of columns that represent categorical variables. We then plot a frequency bar chart to give an overview of the frequency of each level for each categorical variable. These information can provide a context of the data and can inform us whether or not we need to handle missing data. 

We will then explore the distributions of the test scores based on class type to confirm what the study says that students in small classes usually outscore students in regular or regular with aide classes. Then, we want to see whether this phoeomonon holds true on all students with different demographics such as gender, ethnicity, and birthyear. 

### 2.3 One-way Anova Model

To see whether there is a treatment effect of the class type assignment, we will use a one-way ANOVA model. Our one-way ANOVA model is a cell mean model as specified below:

$Y_{ij} = \mu_{i} + \epsilon_{ij}$ where $i = 1,...,l$ and $j = 1,...,n_{i}$

***Explanation of the notation***

* The index $i$ denotes factor level; $l$ is the number of factor level (treatment). In our case we have $l = 3$ since we have 3 different treatment groups: small, regular, and regular with aide class types.

* The index $j$ denotes experimental unit. An experimental unit is a subject to which a treatment is assigned. In our case, each experiemental unit is a 1st-grade student. 

* The index $n_{i}$ is the number of experimental units in the $i$th treatment group. $n_{T} = \sum_{n=1}^{l} n_{i}$ is the total size sample. In our case, $n_{T} = 6600$ as we do not have information about the class type assignment or the test scores for the 1st grade students for some students.

* $Y_{ij}$ denotes the observed outcome of the $j$th experiement unit in the $i$th treatment group. In our study, $Y_{ij}$ represents the quantitative test score of the $j$th student in the $i$th class type. 

* $\mu_{i}$ denotes the $i$th factor level mean. It will be the average of test scores in the population of the ith class type that we try to estimate since these are unknown parameters.

* $\epsilon_{ij}$'s denotes random errors. These are unobserved random variables.

The assumptions of using this one-way ANOVA model are as follows: 

* The random errors are assumed to be identically and independently distributed from a normal distribution with mean $0$ and variance $\sigma^{2}$.

* The outcomes are independent normal random variables with a common variance and with means equal to the respective factor level mean. 


### 2.3 Model Diagnostics

Next, our model diagnostics will confirm whether the assumptions of our one-way ANOVA model hold such that this model is appropriate for the problem setting. We will use a residual plot to see if the residuals (the differences between the actual test scores and predicted test scores) have mean zero and equal variance since these conditions are part of our model assumptions. For the normality assumption, we will use a normal Q-Q plot. For the independece assumption, we would analyze the design of this experiment to justify whether the independence assumption holds or not.  

### 2.4 Hypothesis Testing

Based on the two assumptions of one-way ANOVA model described above, we plan to use F-test to determine whether there is a treatment effect based on class type, that is, whether the test scores have different distributions under different class type assignments. Our null hypothesis for the F-test is that the averages of the test scores under each class type are equal. Upon the rejection of the null hypothesis, we will then investigate the nature of the differences among the test score averages of the class types.

After knowing there is a treatment effect, we may proceed to find out more specific information about where the difference should be accounted by comparing the averages of test scores of two class types at a time. Since the dataset does not have the same number of observations for each class type, it is suggested that we should use Tukey's procedure as it can give us more precise estimation of the difference between the means of test scores from two different class types based on a narrower confidence interval [6].

## 3. Results and Discussion

### 3.1 Descriptive Analysis
#### 3.1.1 Background of the dataset

About the dataset, it has 11598 rows and 13 columns. It has only 13 columns because we only include information that directly describes the 1st grade student cohort. From `figure 1`, we know that there are only 55.2% of all the rows that have no missing values. The total number of missing values in this dataset is 48465, but we don't have any feature that is full of missing values. `Figure 2` shows the percentage of missing values in each feature. We see that there are high proportion of missing values for most of the features.

```{r EDA, echo=FALSE, warning=FALSE, message=FALSE}
#install.packages("AER")
#install.packages("DataExplorer")
#install.packages("multcompView")
# Load packages
library(AER)
library(ggplot2)
library(DataExplorer)
star <- read.csv("star.csv", header=TRUE)
# Keep the columns only relevant to the first grade students
columns <- c("gender","ethnicity","birth","star1","math1","lunch1","school1", "degree1", "ladder1", "experience1", "tethnicity1", "system1", "schoolid1")
data <- star[,columns]
# Change the colnames
colnames(data) <- c("Gender","Ethnicity","Birth", "Class Type", "Test Score", "Lunch", "School","Degree", "Ladder", "Experience", "Teacher Ethnicity", "System", "School ID")

# Plot to give general information about the dataset such as missing values
plot_intro(data, title="Figure 1: Basic Information about the dataset")
plot_missing(data, title= "Figure 2: Missing values proportion")
```

#### 3.1.2 Other Discoveries

In `figure 3`, we show a frequency bar chart to display the frequency of each categorical variable to get a better idea of the demographics related to the 1st student cohort. We see that only some features are roughly balanced (having the same number of frequency for each level of the variable) such as gender, lunch (whether the school provides free lunch or not).We can see that the student cohort is mostly comprised of Caucasian, followed by African American. 
```{r barchart, fig.width=8, fig.height=10, echo=FALSE, warning=FALSE, message=FALSE}
plot_bar(data, title = "Figure 3: Frequency bar charts for all Categorical Variables")
```

From `figure 4`, we see that students in small classes have higher quantiative test scores in general. We then explore this distribution with the demographics of the 1st grade student cohort. Students in small classes also perform better in general regardless of gender as shown by `figure 5`. 

```{r EDA2,echo=FALSE, warning=FALSE, message=FALSE}
data <- star[,columns]
# Boxplot to show the distribution of scores based on only class type
ggplot(data = data[!is.na(data$star1),], mapping = aes(x = star1, y = math1)) +
  geom_boxplot()  +
  labs(title="Figure 4: The distribution of Math Test Scores by Class Type", y = "Math Test Scores", x ="Class Type")

# Boxplot to show the distribution of math scores based on gender and class type
ggplot(data[!is.na(data$gender),], aes(x=gender, y=math1, fill=star1)) + geom_boxplot() +
  labs(title="Figure 5: Math test scores by Gender and Class Type",x="Gender", y = "Math Test Scores") +
  guides(fill=guide_legend(title="Class Type"))
```

However, this phenomenon does not hold for Asian students in the dataset as shown in `figure 6`. We see the Asian students in regular or regular with aide classes outperform the Asian students in small classes in general. Similarly, for those who were born in 1977 and 1978, students in regular or regular with aide classes also outscore students in small classes in general as shown in `figure 7`. 


```{r fig67, echo=FALSE, warning=FALSE, message=FALSE}
# Boxplot to show the distribution of math scores based on ethnicity and class type
ggplot(data[!is.na(data$ethnicity),], aes(x=ethnicity, y=math1, fill=star1)) + 
  geom_boxplot() +
  labs(title="Figure 6: Math test scores by Student's Ethnicity and Class Type",x="Student's Ethnicity", y = "Math Test Scores") +
  guides(fill=guide_legend(title="Class Type"))+
  scale_x_discrete(labels=c("cauc" = "Caucasian", "afam" = "African American","asian" = "Asian", "hispanic" = "Hispanic", "amindian"="Amerindian", "other"="Other"))

data_age <- data[!is.na(data$math1),] 
data_age <- data_age[!is.na(data_age$star1),]
data_age <- data_age[!is.na(data_age$birth),]
data_age$birth <- as.character(data_age$birth)
data_age$birthyear <- read.table(text = data_age$birth, sep = " ", colClasses = "character")[1]
data_age$birthyear <- as.factor(unlist(data_age$birthyear))
# Plot the boxplot
ggplot(data_age, aes(x=birthyear, y=math1, fill=star1)) + 
  geom_boxplot()+
  labs(title="Figure 7: Math test scores by Student's Birthyear and Class Type",x="Student's Birthyear", y = "Math Test Scores")

```


### 3.2 One-way ANOVA model

`Table 1` shows a summary of our anova model. The sum of squares between class types shows the variability among the averages of all class typess, which is 97538. The more similar the average of the test scores of each class type, the smaller this sum of squares tend to be. Within each class type, we can also see that the variation of the outcomes around their respective mean of the class type is also high, which is 12065523. The smaller this value is, the smaller error variance we have. Similar to the usage of F-value, the p-value helps us understand whether there is a difference among all the test score means of each class type or the difference happens due to chance. We will leave the detailed discussion of hypothesis testing in section `3.4` which also utilizes the information from `Table 1`.

**Table 1: ANOVA Table**

|   Source  of variation  |  Degrees of freedom  |   Sum of Squares   |    Mean Square    |    F   |  p-value    |
|:------------|-----:|--------------:|--------------:|-------:|--------------------:|
|  Between Class Types      |  *2* |  195075       |  97538       | 53.33 |  **< 2.2e-16**      |
|  Within Class Type   |  6595  |  12065523       |   1829       |        |                     |

```{r onewayANOVA, include=FALSE}
#data <- star[,columns]
data2 <- data[,c("math1","star1")]
#colnames(data2) <- c("Math Test Scores", "Class Types")
# Linear regression model fit
lmfit <-lm(math1~star1,data=data2)
summary(lmfit)
# One-way ANOVA model
anova.fit<- aov(lmfit)
summary(anova.fit)
```

### 3.3 Model Diagnostics

In this experiment, the study randomly assigned students to small classes, regular classes, and regular classes with aide. Schools enrolled in this study only if its study body is big enough to have at least one class for each class type. In addition, teachers were also randomly assigned to classes. Besides, there is no obvious evidence based on the study description to show that some student's math test scores would have depended on other's students math test scores. Therefore, we have reasons to beleive that the outcomes do not depend on each other.

We can see from the `figure 8` that the residual points scatter around the 0 evenly and the extent of the points scattered are nearly equal. This shows that our model does not violate the assumptions of having zero mean and equal variance.

```{r modelDiag1, echo=FALSE, warning=FALSE, message=FALSE}
# Residual plot
ggplot(lmfit)+
 geom_point(aes(x=.fitted,y=.resid),color="red")+
 labs(title="Figure 8: Residual Plot",x="Class Type",y="residuals")
```

In the `figure9`, it is the distribution of math score of 1st grade students, it shows that a approximately normal distribution pattern of the data. `Figure10` shows a slightly heavy right tailed and light left tailed, concerning that this phenomenon is not serious, so we can conclude that is qualified for the normality assumption. 
```{r historgram, echo=FALSE, warning=FALSE, message=FALSE}
#Histgram of responce variable
ggplot(data=data2[!is.na(data2$math1),],mapping=aes(x=math1))+
  geom_histogram(color="white",fill="black",bins=20)+
  ggtitle("Figure 9: Histogram of math score")
```

**Figure 10: Normal QQ plot**

```{r qqplot, echo=FALSE, warning=FALSE, message=FALSE}
#Q-Q plot
plot(lmfit,which=2)
```

### 3.4 Hypothesis Testing

To conduct a F-test, the first step is to state the null hypothesis $H_{0}$: $\mu_{1}=\mu_{2}=\mu_{3}$, where each $\mu{i}$ represent the average of test scores within each class type. The alternative hypothesis $H_{\alpha}$: not all $\mu_{i}$’s are equal. From `table 1`, we see that the pvalue is$<2.2e-16<0.05$, we therefore reject the null hypothesis at level 0.05 as the p-value suggests that the equality of the means of the test scores of each class type happen less than 5% of the time. Therefore, we conclude that there is a treatment effect of the class types.

Then, we use Tukey's procedure to find out more information where the difference may come from. `Figure 11` gives us an intuition of confidence intervals for the difference in the means for all three pairs of class types. For example, the first confidence interval in the first row is comparing regular class and regular-with-aide class. We see that the difference that we see from F-test are mostly accounted by the differences between small class type and other class types as we see that the interval for the difference between regular and regular aide class types are closest to 0.

From `Table 2`, we can find that this 95% family-wise confidence interval goes from 1.430754 to 7.27072. By comparing the differences between two means for each pair and the adjusted p-value, we see that the difference betwee small classes and the regular classses is the largest.

**Table 2: Tukey Multiple Comparisons of Means**

```{r table2, echo=FALSE, message=FALSE, warnings=FALSE, results='asis'}
tabl <- "
| Pairwise Comparison   | Difference between two means          | Lower Bound       | Upper Bound     | Adjusted p-value     |
|-----------------------|:-------------:|----------:|---------:|----------:|
| Regular+Aide-Regular  | 4.350737      | 1.430754  | 7.27072  | 0.0013965 |
| Small-Regular         | 13.403299     | 10.339053 | 16.46754 | 0.0000000 |
| Small-Regular+Aide    | 9.052562      | 5.906497  | 12.19863 | 0.0000000 |
"
cat(tabl) # output the table in a format good for HTML/PDF/docx conversion
```

```{r Tukey_kramer,echo=FALSE, warning=FALSE, message=FALSE }
# library
#install.packages('multcompView')
library(multcompView)

# Tukey test to study each pair of treatment :
TUKEY <- TukeyHSD(x=anova.fit , conf.level=0.95)
#TUKEY
```

**Figure 11: The Confidence Interval of Multiple Comparisons of Means**

```{r Tukey_plot,echo=FALSE, warning=FALSE, message=FALSE }
# Tuckey test representation :
plot(TukeyHSD(anova.fit), col="brown")
```

### 3.5 Possibility of making any causal statements

The original study often serves as the support of class-size reduction policies since many argue it draws convincing causal statement [2 & 3]. If we believe STAR experiment is a randomized experiment, the treatment’s causal impact can be reflected by the difference in student performance receiving different treatments (class type assignments). With the following assumptions based on the framework of potential outcomes, we can validly make a causal statement between class types and math score.  

- **Stable unit treatment value assumption (SUTVA)**: SUTVA comes in two folds: 1) The treatment assignment of one student does not affect potential outcomes of others. This implies non-interference or no spillover effect. A student math score is not dependent on whether or not other students are assigned to a certain class type. 2) The treatments are stable. Translating into the case of STAR, it simply means that the students assigned to a class type consistently receive education of that class type. This is also satisfied based on the experiment setting.  

<!---$$(Yi(1),\ Yi(0))\ ⊥\ Zj ,\ ∀\ i \neq j$$--->

- **Strong ignorability assumption**: If we further assumes a completely randomized experiment assumption, conditioning on other variables is no longer required. This is realizable under the ideal situation. In the STAR experiment design, students are randomly assigned across treatment groups of different class types. A completely randomized experiment makes sure that other variables, such as ethnicity or gender, do not affect the treatment. Thus the only source of difference in outcome is from the treatment itself. When analyzing the data, we only need to consider the one primary factor, class type, without accounting or adjusting for the other variables.   

  <!----$$(Y0,\ Y1,\ Y2) ⊥ Z\ |\ X$$ 
  
        - Treatment is independent of potential outcomes after conditioning on controls.

  $$(Y0,\ Y1,\ Y2,\ X)\ ⊥\ Z$$ 
  
        - Treatment assignment is independent of potential outcomes and other observed variables.
        
        - Here Z is treatment (class types including reg, small & reg+aid), Y are outcomes (math score), and X are covariates (other variables).----->
        

  Notably, It is not easy to verify the randomization of this experiment. According to the Introduction of Econometrics [4], in an ideal randomized controlled experiment, the following conditions are fulfilled. 1) The subjects are selected at random from the population. 2) The subjects are randomly assigned to treatment and control group. From `figure 3` in descriptive analysis, we can indirectly verify the result of this randomized experiments. 


We can measure the notion of causal effect by looking at the average causal effect. To do so, we can consider the pairwise comparison between the average values of the outcomes based on different class type assignment to if there is a difference. When the assumptions that we described above hold and our analysis has shown that the average differences of the test scores based on different class types are siginificant, we can possibly make some causal statements.

<!----  $$
  \begin{aligned}
  &\ \ \ \ \ E[Y|Z=1]\ –\ E[Y|Z=0] \\
  &= E[Y(1)|Z=1]\ –\ E[Y(0)|Z=0]\  \ \ \ \ \ \ \ (SUTVA)\\
  &= E[Y(1)] – E[Y(0)]\  \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (ignorability)\\
  \end{aligned}
  $$ ---->          

Lastly, we recognize that there are many potential aspects of the experiment that can undermine the above assumptions, such as the unbalanced design for different treatments and many uncertainties and deviations introduced during the impletation [5]. These require researchers to take a closer look at the details of the STAR experiment in further studies.     

## 4. Conclusion

In conclusion, we have come up with a one-way ANOVA model to analyse the treatment of effect of class type based on the quantiative test scores from the 1st-grade student cohort. We have shown that our dataset does not violate the model assumptions. Thus, the model is appropriate for this problem setting.

By the F-test, we show that there is a treatment effect of class types on math test scores. We have also shown that the difference mostly are accounted by the differences between small class type and other class types using Tukey's procedure. We now would like to discuss whether or not any causal statements can be made.

We have also discussed the possibility of making any causal statements based on our analysis. With the assumptions we discuss and the result of the analysis, we are confident that some causal statements can be made based on our analysis.  

## Appendix I. Reference

[1] C.M. Achilles; Helen Pate Bain; Fred Bellott; Jayne Boyd-Zaharias; Jeremy Finn; John Folger; John Johnston; Elizabeth Word, 2008, "Tennessee's Student Teacher Achievement Ratio (STAR) project", https://doi.org/10.7910/DVN/SIWH9F, Harvard Dataverse, V1, UNF:3:Ji2Q+9HCCZAbw3csOdMNdA== [fileUNF]

[2] Webbink, Dinand. "Causal effects in education." Journal of Economic Surveys 19.4 (2005): 535-560.

[3] Konstantopoulos, Spyros. "Do small classes reduce the achievement gap between low and high achievers? Evidence from Project STAR." The Elementary School Journal 108.4 (2008): 275-291.

[4] Stock, James H., and Mark W. Watson. Introduction to econometrics. Vol. 104. Boston: Addison Wesley, 2003.

[5] Hanushek, Eric A. "Some findings from an independent investigation of the Tennessee STAR experiment and from other investigations of class size effects." Educational Evaluation and Policy Analysis 21.2 (1999): 143-163.

[6] Kutner, Michael H(2005). Applied Linear Statistical Models. 0071122214

## Github Repository Link:
https://github.com/kenneth-lee-ch/STA-207

